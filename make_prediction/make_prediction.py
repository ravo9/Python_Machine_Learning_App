# -*- coding: utf-8 -*-
"""Stock Prediction Machine Learning - Close.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hJEOfaoOtXUjxbHaSkz3q1ulMgEY-B7i
"""

# Description: This program uses an artificial recurrent neural network called Long Short Term Memory (LSTM)
#               to predict the price of a particular instrument using the past n day stock price.


import tensorflow as tf
from tensorflow import keras
from array import array
from statistics import *
import math
import pandas_datareader as web
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM
import matplotlib.pyplot as plt
import fileinput
import sys
import os


# Select column: Low, High, Open or Close
column='Close'
# 3.5 months to be tested and 2 months for starting 60 days
startDate='2020-05-15'
endDate='2020-11-13'
instrument = 'GBPUSD=X'
days_into_account = 30
# Best prediction -> 5
# days_into_account = 5

x_test = []
y_test = []

scaler = MinMaxScaler(feature_range=(0,1))

def prepareData():

    global column
    global startDate
    global endDate
    global instrument
    global days_into_account

    global x_test
    global y_test

    global scaler

    # Get the data
    df = web.DataReader(instrument, data_source='yahoo', start=startDate, end=endDate)

    # Create a new dataframe with only our column
    data = df.filter([column])

    # Convert the dataframe to Numpy array
    dataset = data.values

    # Scale the data
    scaled_data = scaler.fit_transform(dataset)

    # Create the testing data set
    test_data = scaled_data

    # Create the data sets x_test and y_test
    y_test = dataset[days_into_account:, :]

    for i in range(days_into_account, len(test_data)):
      x_test.append(test_data[i-days_into_account:i, 0])

    # Convert the data into Numpy array
    x_test = np.array(x_test)

    # Reshape the data
    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))


# Main function

prepareData()

# Check predictions
# 1. Load models
models = list()
pathToModel = 'models/'
modelsNames = os.listdir(pathToModel)
modelsNames.sort()

print(modelsNames)

for modelName in modelsNames:
    if os.path.isdir(pathToModel + modelName):
        filename = pathToModel + modelName
        model = keras.models.load_model(filename)
        models.append(model)

# 2. Get all predictions
predictions = [model.predict(x_test) for model in models]
scaledPredictions = []
for prediction in predictions:
    scaledPrediction = scaler.inverse_transform(prediction)
    scaledPredictions.append(scaledPrediction)

for prediction in scaledPredictions:
    print("AVERAGE ERROR:")
    average = np.average(np.abs(prediction - y_test))
    print(average)
    print()

# 3. Calculate average
meanPrediction = np.mean(scaledPredictions, axis=0)

# 4. Compare results
print("AVERAGE ENSEBLE ERROR:")
averageEnsemble = np.average(np.abs(meanPrediction - y_test))
print(averageEnsemble)
print()

np.savetxt("average_error_data.csv", np.abs(meanPrediction - y_test), delimiter=",")

# 5. Print prediction for next day
print("Prediction for the next day: ")
apple_quote = web.DataReader(instrument, data_source='yahoo', start=startDate, end=endDate)
new_df = apple_quote.filter([column])
last_n_days = new_df[-days_into_account:].values
last_n_days_scaled = scaler.transform(last_n_days)
X_test = []
X_test.append(last_n_days_scaled)
X_test = np.array(X_test)
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))
pred_price = model.predict(X_test)
pred_price = scaler.inverse_transform(pred_price)
print(pred_price)
